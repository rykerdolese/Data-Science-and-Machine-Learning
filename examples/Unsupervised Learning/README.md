## Unsupervised Learning

This folder contains from-scratch implementations of **unsupervised learning algorithms**. Unlike supervised learning, these models work with **unlabeled data**, meaning there is no ground-truth output provided. The goal is to discover hidden structure, patterns, or relationships within the data.

Unsupervised learning is commonly used for **clustering**, **dimensionality reduction**, and **anomaly detection**.

### Common Use Cases
- Customer segmentation
- Pattern discovery in high-dimensional data
- Data compression and visualization
- Noise reduction and feature extraction
- Outlier and anomaly detection

### Algorithms Included
- K-Means Clustering
- DBSCAN
- Principal Component Analysis (PCA)
- Label Propogation (Community Detection)

### Typical Workflow
1. Preprocess and scale the data  
2. Fit the model to the unlabeled dataset  
3. Analyze the learned structure (clusters or components)  
4. Use results for visualization, downstream modeling, or insight generation  

These implementations emphasize clarity and conceptual understanding, making them suitable for learning how unsupervised algorithms work under the hood rather than serving as optimized production-ready tools.

